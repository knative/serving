# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: v1
kind: ConfigMap
metadata:
  name: ela-config
  namespace: ela-system
data:
  # These are example settings of domain.
  # prod-domain.com will be used for routes having app=prod.
  prod-domain.com: |
    selector:
      app: prod
  # Default value for domain, for routes that does not have app=prod labels.
  # Although it will match all routes, it is the least-specific rule so it
  # will only be used if no other domain matches.
  demo-domain.com: |

  # AUTOSCALER CONFIGURATION

  # Static parameters:

  # Target concurrency is the desired number of concurrent requests for
  # each pod. This is the primary knob for fast autoscaling which will
  # try achieve an concurrency per pod of the target
  # concurrency. Single-concurrency must target a value close to 1.0.
  autoscale.multi-concurrency-target: "1.0"
  autoscale.single-concurrency-target: "0.9"

  # When operating in a stable mode, the autoscaler operates on the
  # average concurrency over the stable window.
  autoscale.stable-window: "60s"

  # When observed average concurrency during the panic window reaches 2x
  # the target concurrency, the autoscaler enters panic mode. When
  # operating in panic mode, the autoscaler operates on the average
  # concurrency over the panic window.
  autoscale.panic-window: "6s"

  # Max scale up rate limits the rate at which the autoscaler will
  # increase pod count. It is the maximum ratio of desired pods versus
  # observed pods.
  autoscale.max-scale-up-rate: "10"

  # Concurrency quantum of time is the minimum time a request consumes
  # for the purpose of reporting concurrency metrics. The number of
  # quantums of time that fit into 1 second determines the max QPS the
  # pod will handle. Requests can span multiple quantums of time in
  # which case the request duration is rounded up.
  autoscale.concurrency-quantum-of-time: "100ms"

  # Scale to zero feature flag
  autoscale.enable-scale-to-zero: "false"

  # Dynamic parameters (take effect when config map is updated):

  # Scale to zero threshold is the time a revision must be idle before
  # it is scaled to zero.
  autoscale.scale-to-zero-threshold: "5m"


  # LOGGING CONFIGURATION

  # Static parameters:

  # A fluentd sidecar will be set up to collect var log if this flag is true.
  logging.enable-var-log-collection: "true"

  # The fluentd sidecar image used to collect logs from /var/log as a sidecar.
  # Must be presented if logging.enable-var-log-collection is true.
  logging.fluentd-sidecar-image: "k8s.gcr.io/fluentd-elasticsearch:v2.0.4"

  # The fluentd sidecar output config to specify logging destination.
  logging.fluentd-sidecar-output-config: |
    <match **>
      @id elasticsearch
      @type elasticsearch
      @log_level info
      include_tag_key true
      # Elasticsearch service is in monitoring namespace.
      host elasticsearch-logging.monitoring
      port 9200
      logstash_format true
      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.system.buffer
        flush_mode interval
        retry_type exponential_backoff
        flush_thread_count 2
        flush_interval 5s
        retry_forever
        retry_max_interval 30
        chunk_limit_size 2M
        queue_limit_length 8
        overflow_action block
      </buffer>
    </match>

  # The revision log url template, where ${REVISION_UID} will be replaced by the actual
  # revision uid. For the url to work you'll need to set up monitoring and have access to
  # the kibana dashboard using `kubectl proxy`.
  logging.revision-url-template: |
    http://localhost:8001/api/v1/namespaces/monitoring/services/kibana-logging/proxy/app/kibana#/discover?_a=(query:(match:(kubernetes.labels.knative-dev%2FrevisionUID:(query:'${REVISION_UID}',type:phrase))))

  # Configuration for Elafros controllers
  logging.ela-controller.zap-config: |
    {
      "level": "info",
      "development": false,
      "sampling": {
        "initial": 100,
        "thereafter": 100
      },
      "outputPaths": ["stdout"],
      "errorOutputPaths": ["stderr"],
      "encoding": "json",
      "encoderConfig": {
        "timeKey": "",
        "levelKey": "level",
        "nameKey": "logger",
        "callerKey": "caller",
        "messageKey": "msg",
        "stacktraceKey": "stacktrace",
        "lineEnding": "",
        "levelEncoder": "",
        "timeEncoder": "",
        "durationEncoder": "",
        "callerEncoder": ""
      }
    }
