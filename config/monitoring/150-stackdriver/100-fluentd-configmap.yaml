# Copyright 2018 The Knative Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

kind: ConfigMap
apiVersion: v1
metadata:
  name: fluentd-ds-config
  namespace: monitoring
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
data:
  100.system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
    </system>
  200.containers.input.conf: |-
    <source>
      @id fluentd-containers.log
      @type tail
      path /var/log/containers/*user-container-*.log,/var/log/containers/*build-step-*.log,/var/log/containers/controller-*controller-*.log,/var/log/containers/webhook-*webhook-*.log,/var/log/containers/*autoscaler-*autoscaler-*.log,/var/log/containers/*queue-proxy-*.log,/var/log/containers/activator-*activator-*.log
      pos_file /var/log/es-containers.log.pos
      time_format %Y-%m-%dT%H:%M:%S.%NZ
      # Tags at this point are in the format of:
      # 'raw.reform.kubernetes.<POD_NAME>_<NAMESPACE_NAME>_<CONTAINER_NAME>-<CONTAINER_ID>.log'.
      tag raw.reform.kubernetes.*
      format json
      read_from_head true
    </source>
    # Combine multi line logs which form an exception stack trace into a single log entry
    <match raw.reform.kubernetes.**>
      @id raw.reform.kubernetes
      @type detect_exceptions
      # Tags at this point are in the format of:
      # 'reform.kubernetes.<POD_NAME>_<NAMESPACE_NAME>_<CONTAINER_NAME>-<CONTAINER_ID>.log'.
      remove_tag_prefix raw
      message log
      stream stream
      multiline_flush_interval 5
      max_bytes 500000
      max_lines 1000
    </match>
    # Add Kubernetes metadata
    <filter reform.kubernetes.**>
      @type kubernetes_metadata
      merge_json_log false # Don't parse json log
      preserve_json_log false
    </filter>
    <match reform.kubernetes.**>
      @type record_reformer
      enable_ruby true
      # Tags at this point are in the format of:
      # 'kubernetes.<POD_NAME>_<NAMESPACE_NAME>_<CONTAINER_NAME>'.
      # which is the format google_cloud uses to extac basic information
      tag kubernetes.${tag_suffix[4].split('-')[0..-2].join('-')}
      remove_keys _dummy_
      # In GKE resource type, pod_id actually is pod_name, and namespace_id is namespace_name
      <record>
        _dummy_ ${record['kubernetes']["pod_id"] = record['kubernetes']["pod_name"]; record['kubernetes']["namespace_id"] = record['kubernetes']["namespace_name"]; nil}
      </record>
    </match>
  300.forward.input.conf: |-
    # Takes the messages sent over TCP, e.g. request logs from Istio
    <source>
      @type forward
      port 24224
    </source>
  900.output.conf: |-
    # Send to Stackdriver
    # google_cloud plugin moves `kubernetes` metadata to `labels`.
    <match **>
      @type google_cloud

      # Try to detect JSON formatted log entries.
      detect_json true
      # Allow log entries from multiple containers to be sent in the same request.
      split_logs_by_tag false
      # Set the buffer type to file to improve the reliability and reduce the memory consumption
      buffer_type file
      buffer_path /var/log/fluentd-buffers/kubernetes.containers.buffer
      # Set queue_full action to block because we want to pause gracefully
      # in case of the off-the-limits load instead of throwing an exception
      buffer_queue_full_action block
      # Set the chunk limit conservatively to avoid exceeding the recommended
      # chunk size of 5MB per write request.
      buffer_chunk_limit 1M
      # Cap the combined memory usage of this buffer and the one below to
      # 1MiB/chunk * (6 + 2) chunks = 8 MiB
      buffer_queue_limit 6
      # Never wait more than 5 seconds before flushing logs in the non-error case.
      flush_interval 5s
      # Never wait longer than 30 seconds between retries.
      max_retry_wait 30
      # Disable the limit on the number of retries (retry forever).
      disable_retry_limit
      # Use multiple threads for processing.
      num_threads 2
      use_grpc true
    </match>
